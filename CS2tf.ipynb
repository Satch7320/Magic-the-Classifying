{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from processing import get_data\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA, NMF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split as TTS\n",
    "\n",
    "import statsmodels.regression as smr\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get cleaned data\n",
    "data = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>released_at</th>\n",
       "      <th>mana_cost</th>\n",
       "      <th>cmc</th>\n",
       "      <th>type_line</th>\n",
       "      <th>oracle_text</th>\n",
       "      <th>power</th>\n",
       "      <th>toughness</th>\n",
       "      <th>colors</th>\n",
       "      <th>color_identity</th>\n",
       "      <th>keywords</th>\n",
       "      <th>set</th>\n",
       "      <th>rarity</th>\n",
       "      <th>flavor_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fury Sliver</td>\n",
       "      <td>2006-10-06</td>\n",
       "      <td>{5}{R}</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Creature — Sliver</td>\n",
       "      <td>All Sliver creatures have double strike.</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>['R']</td>\n",
       "      <td>['R']</td>\n",
       "      <td>[]</td>\n",
       "      <td>tsp</td>\n",
       "      <td>uncommon</td>\n",
       "      <td>\"A rift opened, and our arrows were abruptly s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kor Outfitter</td>\n",
       "      <td>2009-10-02</td>\n",
       "      <td>{W}{W}</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Creature — Kor Soldier</td>\n",
       "      <td>When Kor Outfitter enters the battlefield, you...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>['W']</td>\n",
       "      <td>['W']</td>\n",
       "      <td>[]</td>\n",
       "      <td>zen</td>\n",
       "      <td>common</td>\n",
       "      <td>\"We take only what we need to survive. Believe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            name released_at mana_cost  cmc               type_line  \\\n",
       "0    Fury Sliver  2006-10-06    {5}{R}  6.0       Creature — Sliver   \n",
       "1  Kor Outfitter  2009-10-02    {W}{W}  2.0  Creature — Kor Soldier   \n",
       "\n",
       "                                         oracle_text power toughness colors  \\\n",
       "0           All Sliver creatures have double strike.     3         3  ['R']   \n",
       "1  When Kor Outfitter enters the battlefield, you...     2         2  ['W']   \n",
       "\n",
       "  color_identity keywords  set    rarity  \\\n",
       "0          ['R']       []  tsp  uncommon   \n",
       "1          ['W']       []  zen    common   \n",
       "\n",
       "                                         flavor_text  \n",
       "0  \"A rift opened, and our arrows were abruptly s...  \n",
       "1  \"We take only what we need to survive. Believe...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsets = ['und', 'ust', 'unh', 'ugl']\n",
    "indices = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for abb in unsets:\n",
    "    indices.append(data[data['set'] == abb].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for unset in indices:\n",
    "    data.drop(index = unset, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_training, X_testing = TTS(data)\n",
    "X_training, X_validating = TTS(X_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data['cmc'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A utility method to create a tf.data dataset from a Pandas Dataframe\n",
    "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
    "  dataframe = dataframe.copy()\n",
    "  labels = dataframe.pop('cmc')\n",
    "  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "  ds = ds.batch(batch_size)\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_training = df_to_dataset(X_training)\n",
    "experiment_testing = df_to_dataset(X_testing)\n",
    "experiment_validating = df_to_dataset(X_validating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = []\n",
    "for row in X_training.itertuples(index = False):\n",
    "    string = ''\n",
    "    for term in row:\n",
    "        string += f' {term}'\n",
    "    train_list.append(string)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = []\n",
    "for row in X_testing.itertuples(index = False):\n",
    "    string = ''\n",
    "    for term in row:\n",
    "        string += f' {term}'\n",
    "    test_list.append(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_list = []\n",
    "for row in X_validating.itertuples(index = False):\n",
    "    string = ''\n",
    "    for term in row:\n",
    "        string += f' {term}'\n",
    "    val_list.append(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_np = np.array(train_list).reshape(-1,1)\n",
    "test_np = np.array(test_list).reshape(-1,1)\n",
    "val_np = np.array(val_list).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_in = tf.cast(train_list, tf.string)\n",
    "y_in = tf.cast(target.values[X_training.index], tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = tf.cast(val_list, tf.string)\n",
    "y_val = tf.cast(target.values[X_validating.index], tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert DataFrame to tf DataSet, splitting to create train test sets\n",
    "tf_train_data = tf.data.Dataset.from_tensor_slices((x_in, y_in))\n",
    "tf_val_data = tf.data.Dataset.from_tensor_slices((x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 1000\n",
    "encoder = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE,\n",
    "    standardize = 'lower_and_strip_punctuation',\n",
    "    output_mode = 'tf-idf',\n",
    "    #output_sequence_length = 200\n",
    "    )\n",
    "encoder.adapt(tf_train_data.map(lambda x, y: x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = encoder.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_text(text, label):\n",
    "  text = tf.expand_dims(text, -1)\n",
    "  return encoder(text), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_train = tf_train_data.batch(32).map(vectorize_text)\n",
    "mapped_val = tf_val_data.batch(32).map(vectorize_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle data for training and create batches of (text, label) pairs\n",
    "train_ds = mapped_train.cache().prefetch(buffer_size = tf.data.AUTOTUNE)\n",
    "val_ds = mapped_val.cache().prefetch(buffer_size = tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indicator_columns\n",
    "# indicator_column_names = data.columns\n",
    "# for col_name in indicator_column_names:\n",
    "#   categorical_column = feature_column.categorical_column_with_vocabulary_list(\n",
    "#       col_name, dataframe[col_name].unique())\n",
    "#   indicator_column = feature_column.indicator_column(categorical_column)\n",
    "#   feature_columns.append(indicator_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding columns\n",
    "# breed1 = feature_column.categorical_column_with_vocabulary_list(\n",
    "#       'Breed1', dataframe.Breed1.unique())\n",
    "# breed1_embedding = feature_column.embedding_column(breed1, dimension=8)\n",
    "# feature_columns.append(breed1_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crossed columns\n",
    "# age_type_feature = feature_column.crossed_column([age_buckets, animal_type], hash_bucket_size=100)\n",
    "# feature_columns.append(feature_column.indicator_column(age_type_feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = []\n",
    "for column in data.columns:\n",
    "    if column == 'cmc':\n",
    "        continue\n",
    "    inner = feature_column.categorical_column_with_vocabulary_list(column, data[column].unique())\n",
    "    feature_columns.append(feature_column.embedding_column(inner, dimension = int(len(data[column].unique())**.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 128)         160000    \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (None, None, 128)         99072     \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 128)               99072     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                4128      \n",
      "=================================================================\n",
      "Total params: 362,272\n",
      "Trainable params: 362,272\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(len(vocab)+250, 128,\n",
    "                             input_shape=[None]),\n",
    "#     encoder,\n",
    "    tf.keras.layers.GRU(128, return_sequences=True),\n",
    "    tf.keras.layers.GRU(128),\n",
    "    tf.keras.layers.Dense(32, activation = 'softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "             optimizer = tf.keras.optimizers.Adam(1e-4),\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "977/977 - 910s - loss: 2.1289 - accuracy: 0.1989 - val_loss: 2.0184 - val_accuracy: 0.2003\n",
      "Epoch 2/100\n",
      "977/977 - 906s - loss: 2.0241 - accuracy: 0.2016 - val_loss: 2.0167 - val_accuracy: 0.2003\n",
      "Epoch 3/100\n",
      "977/977 - 905s - loss: 2.0229 - accuracy: 0.2027 - val_loss: 2.0157 - val_accuracy: 0.2000\n",
      "Epoch 4/100\n",
      "977/977 - 905s - loss: 2.0205 - accuracy: 0.2032 - val_loss: 2.0090 - val_accuracy: 0.1999\n",
      "Epoch 5/100\n",
      "977/977 - 903s - loss: 1.9563 - accuracy: 0.2433 - val_loss: 1.8689 - val_accuracy: 0.2782\n",
      "Epoch 6/100\n",
      "977/977 - 903s - loss: 1.8471 - accuracy: 0.2885 - val_loss: 1.8290 - val_accuracy: 0.2919\n",
      "Epoch 7/100\n",
      "977/977 - 925s - loss: 1.8239 - accuracy: 0.2946 - val_loss: 1.8168 - val_accuracy: 0.2964\n",
      "Epoch 8/100\n",
      "977/977 - 925s - loss: 1.8129 - accuracy: 0.2989 - val_loss: 1.8086 - val_accuracy: 0.2997\n",
      "Epoch 9/100\n",
      "977/977 - 923s - loss: 1.8049 - accuracy: 0.3038 - val_loss: 1.7995 - val_accuracy: 0.3044\n",
      "Epoch 10/100\n",
      "977/977 - 877s - loss: 1.7953 - accuracy: 0.3098 - val_loss: 1.7887 - val_accuracy: 0.3062\n",
      "Epoch 11/100\n",
      "977/977 - 948s - loss: 1.7832 - accuracy: 0.3164 - val_loss: 1.7751 - val_accuracy: 0.3086\n",
      "Epoch 12/100\n",
      "977/977 - 861s - loss: 1.7695 - accuracy: 0.3223 - val_loss: 1.7582 - val_accuracy: 0.3208\n",
      "Epoch 13/100\n",
      "977/977 - 851s - loss: 1.7526 - accuracy: 0.3268 - val_loss: 1.7327 - val_accuracy: 0.3266\n",
      "Epoch 14/100\n",
      "977/977 - 851s - loss: 1.7281 - accuracy: 0.3374 - val_loss: 1.7118 - val_accuracy: 0.3411\n",
      "Epoch 15/100\n",
      "977/977 - 851s - loss: 1.7024 - accuracy: 0.3519 - val_loss: 1.6847 - val_accuracy: 0.3604\n",
      "Epoch 16/100\n",
      "977/977 - 851s - loss: 1.6700 - accuracy: 0.3666 - val_loss: 1.6512 - val_accuracy: 0.3734\n",
      "Epoch 17/100\n",
      "977/977 - 851s - loss: 1.6385 - accuracy: 0.3758 - val_loss: 1.6174 - val_accuracy: 0.3807\n",
      "Epoch 18/100\n",
      "977/977 - 852s - loss: 1.6066 - accuracy: 0.3865 - val_loss: 1.5967 - val_accuracy: 0.3840\n",
      "Epoch 19/100\n",
      "977/977 - 851s - loss: 1.5838 - accuracy: 0.3923 - val_loss: 1.5711 - val_accuracy: 0.3954\n",
      "Epoch 20/100\n",
      "977/977 - 851s - loss: 1.5690 - accuracy: 0.3973 - val_loss: 1.5476 - val_accuracy: 0.3984\n",
      "Epoch 21/100\n",
      "977/977 - 853s - loss: 1.5505 - accuracy: 0.4027 - val_loss: 1.5345 - val_accuracy: 0.4028\n",
      "Epoch 22/100\n",
      "977/977 - 851s - loss: 1.5373 - accuracy: 0.4082 - val_loss: 1.5218 - val_accuracy: 0.4081\n",
      "Epoch 23/100\n",
      "977/977 - 851s - loss: 1.5242 - accuracy: 0.4119 - val_loss: 1.5111 - val_accuracy: 0.4098\n",
      "Epoch 24/100\n",
      "977/977 - 853s - loss: 1.5111 - accuracy: 0.4159 - val_loss: 1.4958 - val_accuracy: 0.4167\n",
      "Epoch 25/100\n",
      "977/977 - 853s - loss: 1.4969 - accuracy: 0.4209 - val_loss: 1.4809 - val_accuracy: 0.4210\n",
      "Epoch 26/100\n",
      "977/977 - 853s - loss: 1.4838 - accuracy: 0.4237 - val_loss: 1.4691 - val_accuracy: 0.4232\n",
      "Epoch 27/100\n",
      "977/977 - 854s - loss: 1.4717 - accuracy: 0.4281 - val_loss: 1.4594 - val_accuracy: 0.4261\n",
      "Epoch 28/100\n",
      "977/977 - 853s - loss: 1.4601 - accuracy: 0.4322 - val_loss: 1.4501 - val_accuracy: 0.4336\n",
      "Epoch 29/100\n",
      "977/977 - 853s - loss: 1.4480 - accuracy: 0.4348 - val_loss: 1.4412 - val_accuracy: 0.4376\n",
      "Epoch 30/100\n",
      "977/977 - 854s - loss: 1.4353 - accuracy: 0.4364 - val_loss: 1.4307 - val_accuracy: 0.4388\n",
      "Epoch 31/100\n",
      "977/977 - 854s - loss: 1.4225 - accuracy: 0.4409 - val_loss: 1.4173 - val_accuracy: 0.4412\n",
      "Epoch 32/100\n",
      "977/977 - 853s - loss: 1.4097 - accuracy: 0.4470 - val_loss: 1.4032 - val_accuracy: 0.4446\n",
      "Epoch 33/100\n",
      "977/977 - 856s - loss: 1.3960 - accuracy: 0.4525 - val_loss: 1.3893 - val_accuracy: 0.4510\n",
      "Epoch 34/100\n",
      "977/977 - 853s - loss: 1.3822 - accuracy: 0.4572 - val_loss: 1.3734 - val_accuracy: 0.4563\n",
      "Epoch 35/100\n",
      "977/977 - 854s - loss: 1.3689 - accuracy: 0.4597 - val_loss: 1.3626 - val_accuracy: 0.4621\n",
      "Epoch 36/100\n",
      "977/977 - 853s - loss: 1.3563 - accuracy: 0.4645 - val_loss: 1.3545 - val_accuracy: 0.4664\n",
      "Epoch 37/100\n",
      "977/977 - 854s - loss: 1.3442 - accuracy: 0.4678 - val_loss: 1.3472 - val_accuracy: 0.4702\n",
      "Epoch 38/100\n",
      "977/977 - 853s - loss: 1.3330 - accuracy: 0.4731 - val_loss: 1.3383 - val_accuracy: 0.4747\n",
      "Epoch 39/100\n",
      "977/977 - 853s - loss: 1.3221 - accuracy: 0.4777 - val_loss: 1.3298 - val_accuracy: 0.4775\n",
      "Epoch 40/100\n",
      "977/977 - 853s - loss: 1.3121 - accuracy: 0.4814 - val_loss: 1.3239 - val_accuracy: 0.4783\n",
      "Epoch 41/100\n",
      "977/977 - 854s - loss: 1.3020 - accuracy: 0.4861 - val_loss: 1.3173 - val_accuracy: 0.4799\n",
      "Epoch 42/100\n",
      "977/977 - 853s - loss: 1.2927 - accuracy: 0.4896 - val_loss: 1.3118 - val_accuracy: 0.4822\n",
      "Epoch 43/100\n",
      "977/977 - 853s - loss: 1.2832 - accuracy: 0.4944 - val_loss: 1.3053 - val_accuracy: 0.4854\n",
      "Epoch 44/100\n",
      "977/977 - 853s - loss: 1.2741 - accuracy: 0.4976 - val_loss: 1.2981 - val_accuracy: 0.4897\n",
      "Epoch 45/100\n",
      "977/977 - 853s - loss: 1.2646 - accuracy: 0.5011 - val_loss: 1.2910 - val_accuracy: 0.4929\n",
      "Epoch 46/100\n",
      "977/977 - 853s - loss: 1.2554 - accuracy: 0.5048 - val_loss: 1.2835 - val_accuracy: 0.4981\n",
      "Epoch 47/100\n",
      "977/977 - 853s - loss: 1.2461 - accuracy: 0.5101 - val_loss: 1.2778 - val_accuracy: 0.5012\n",
      "Epoch 48/100\n",
      "977/977 - 853s - loss: 1.2359 - accuracy: 0.5153 - val_loss: 1.2734 - val_accuracy: 0.5036\n",
      "Epoch 49/100\n",
      "977/977 - 957s - loss: 1.2259 - accuracy: 0.5204 - val_loss: 1.2652 - val_accuracy: 0.5091\n",
      "Epoch 50/100\n",
      "977/977 - 1596s - loss: 1.2154 - accuracy: 0.5279 - val_loss: 1.2543 - val_accuracy: 0.5137\n",
      "Epoch 51/100\n",
      "977/977 - 1763s - loss: 1.2027 - accuracy: 0.5356 - val_loss: 1.2448 - val_accuracy: 0.5226\n",
      "Epoch 52/100\n",
      "977/977 - 1675s - loss: 1.1902 - accuracy: 0.5448 - val_loss: 1.2328 - val_accuracy: 0.5336\n",
      "Epoch 53/100\n",
      "977/977 - 1611s - loss: 1.1694 - accuracy: 0.5607 - val_loss: 1.2144 - val_accuracy: 0.5506\n",
      "Epoch 54/100\n",
      "977/977 - 2122s - loss: 1.1240 - accuracy: 0.5936 - val_loss: 1.1210 - val_accuracy: 0.6134\n",
      "Epoch 55/100\n",
      "977/977 - 1768s - loss: 0.9873 - accuracy: 0.6669 - val_loss: 0.9338 - val_accuracy: 0.6874\n",
      "Epoch 56/100\n",
      "977/977 - 1576s - loss: 0.8542 - accuracy: 0.7142 - val_loss: 0.8289 - val_accuracy: 0.7219\n",
      "Epoch 57/100\n",
      "977/977 - 1433s - loss: 0.7728 - accuracy: 0.7437 - val_loss: 0.7773 - val_accuracy: 0.7373\n",
      "Epoch 58/100\n",
      "977/977 - 1551s - loss: 0.7080 - accuracy: 0.7667 - val_loss: 0.7141 - val_accuracy: 0.7640\n",
      "Epoch 59/100\n",
      "977/977 - 1302s - loss: 0.6559 - accuracy: 0.7871 - val_loss: 0.6590 - val_accuracy: 0.7889\n",
      "Epoch 60/100\n",
      "977/977 - 1338s - loss: 0.6036 - accuracy: 0.8051 - val_loss: 0.6220 - val_accuracy: 0.8022\n",
      "Epoch 61/100\n",
      "977/977 - 1311s - loss: 0.5484 - accuracy: 0.8253 - val_loss: 0.5437 - val_accuracy: 0.8320\n",
      "Epoch 62/100\n",
      "977/977 - 1291s - loss: 0.4942 - accuracy: 0.8430 - val_loss: 0.4826 - val_accuracy: 0.8520\n",
      "Epoch 63/100\n",
      "977/977 - 1295s - loss: 0.4348 - accuracy: 0.8638 - val_loss: 0.4158 - val_accuracy: 0.8770\n",
      "Epoch 64/100\n",
      "977/977 - 1301s - loss: 0.3753 - accuracy: 0.8856 - val_loss: 0.4055 - val_accuracy: 0.8803\n",
      "Epoch 65/100\n",
      "977/977 - 1413s - loss: 0.3185 - accuracy: 0.9049 - val_loss: 0.2898 - val_accuracy: 0.9160\n",
      "Epoch 66/100\n",
      "977/977 - 1666s - loss: 0.2759 - accuracy: 0.9184 - val_loss: 0.2469 - val_accuracy: 0.9304\n",
      "Epoch 67/100\n",
      "977/977 - 2078s - loss: 0.2425 - accuracy: 0.9291 - val_loss: 0.2278 - val_accuracy: 0.9372\n",
      "Epoch 68/100\n",
      "977/977 - 1526s - loss: 0.2230 - accuracy: 0.9370 - val_loss: 0.2289 - val_accuracy: 0.9356\n",
      "Epoch 69/100\n",
      "977/977 - 1591s - loss: 0.2029 - accuracy: 0.9413 - val_loss: 0.1909 - val_accuracy: 0.9479\n",
      "Epoch 70/100\n",
      "977/977 - 1640s - loss: 0.1805 - accuracy: 0.9502 - val_loss: 0.1935 - val_accuracy: 0.9489\n",
      "Epoch 71/100\n",
      "977/977 - 985s - loss: 0.1691 - accuracy: 0.9525 - val_loss: 0.1497 - val_accuracy: 0.9618\n",
      "Epoch 72/100\n",
      "977/977 - 861s - loss: 0.1576 - accuracy: 0.9563 - val_loss: 0.1498 - val_accuracy: 0.9601\n",
      "Epoch 73/100\n",
      "977/977 - 861s - loss: 0.1497 - accuracy: 0.9589 - val_loss: 0.1507 - val_accuracy: 0.9608\n",
      "Epoch 74/100\n",
      "977/977 - 891s - loss: 0.1319 - accuracy: 0.9633 - val_loss: 0.1338 - val_accuracy: 0.9656\n",
      "Epoch 75/100\n",
      "977/977 - 973s - loss: 0.1420 - accuracy: 0.9607 - val_loss: 0.1225 - val_accuracy: 0.9672\n",
      "Epoch 76/100\n",
      "977/977 - 967s - loss: 0.1296 - accuracy: 0.9637 - val_loss: 0.1642 - val_accuracy: 0.9579\n",
      "Epoch 77/100\n",
      "977/977 - 938s - loss: 0.1181 - accuracy: 0.9676 - val_loss: 0.3355 - val_accuracy: 0.9122\n",
      "Epoch 78/100\n",
      "977/977 - 855s - loss: 0.1177 - accuracy: 0.9671 - val_loss: 0.1035 - val_accuracy: 0.9727\n",
      "Epoch 79/100\n",
      "977/977 - 853s - loss: 0.1081 - accuracy: 0.9699 - val_loss: 0.1015 - val_accuracy: 0.9726\n",
      "Epoch 80/100\n",
      "977/977 - 950s - loss: 0.1128 - accuracy: 0.9690 - val_loss: 0.2351 - val_accuracy: 0.9375\n",
      "Epoch 81/100\n",
      "977/977 - 850s - loss: 0.1007 - accuracy: 0.9719 - val_loss: 0.0926 - val_accuracy: 0.9756\n",
      "Epoch 82/100\n",
      "977/977 - 851s - loss: 0.1001 - accuracy: 0.9717 - val_loss: 0.0902 - val_accuracy: 0.9753\n",
      "Epoch 83/100\n",
      "977/977 - 949s - loss: 0.0923 - accuracy: 0.9741 - val_loss: 0.0889 - val_accuracy: 0.9762\n",
      "Epoch 84/100\n",
      "977/977 - 851s - loss: 0.0870 - accuracy: 0.9754 - val_loss: 0.0800 - val_accuracy: 0.9779\n",
      "Epoch 85/100\n",
      "977/977 - 948s - loss: 0.0872 - accuracy: 0.9760 - val_loss: 0.0899 - val_accuracy: 0.9755\n",
      "Epoch 86/100\n",
      "977/977 - 850s - loss: 0.0931 - accuracy: 0.9743 - val_loss: 0.0821 - val_accuracy: 0.9771\n",
      "Epoch 87/100\n",
      "977/977 - 918s - loss: 0.0858 - accuracy: 0.9764 - val_loss: 0.0752 - val_accuracy: 0.9799\n",
      "Epoch 88/100\n",
      "977/977 - 984s - loss: 0.0814 - accuracy: 0.9779 - val_loss: 0.0682 - val_accuracy: 0.9812\n",
      "Epoch 89/100\n",
      "977/977 - 953s - loss: 0.0745 - accuracy: 0.9796 - val_loss: 0.0729 - val_accuracy: 0.9802\n",
      "Epoch 90/100\n",
      "977/977 - 958s - loss: 0.0884 - accuracy: 0.9763 - val_loss: 0.0694 - val_accuracy: 0.9805\n",
      "Epoch 91/100\n",
      "977/977 - 950s - loss: 0.0697 - accuracy: 0.9806 - val_loss: 0.0722 - val_accuracy: 0.9802\n",
      "Epoch 92/100\n",
      "977/977 - 900s - loss: 0.0635 - accuracy: 0.9825 - val_loss: 0.0719 - val_accuracy: 0.9801\n",
      "Epoch 93/100\n",
      "977/977 - 947s - loss: 0.0833 - accuracy: 0.9787 - val_loss: 0.0656 - val_accuracy: 0.9818\n",
      "Epoch 94/100\n",
      "977/977 - 897s - loss: 0.0599 - accuracy: 0.9839 - val_loss: 0.1998 - val_accuracy: 0.9484\n",
      "Epoch 95/100\n",
      "977/977 - 953s - loss: 0.0525 - accuracy: 0.9852 - val_loss: 0.0645 - val_accuracy: 0.9834\n",
      "Epoch 96/100\n",
      "977/977 - 880s - loss: 0.0661 - accuracy: 0.9822 - val_loss: 0.0661 - val_accuracy: 0.9827\n",
      "Epoch 97/100\n",
      "977/977 - 851s - loss: 0.0640 - accuracy: 0.9825 - val_loss: 0.0719 - val_accuracy: 0.9799\n",
      "Epoch 98/100\n",
      "977/977 - 851s - loss: 0.0498 - accuracy: 0.9861 - val_loss: 0.0561 - val_accuracy: 0.9849\n",
      "Epoch 99/100\n",
      "977/977 - 851s - loss: 0.0604 - accuracy: 0.9831 - val_loss: 0.0585 - val_accuracy: 0.9832\n",
      "Epoch 100/100\n",
      "977/977 - 851s - loss: 0.0454 - accuracy: 0.9876 - val_loss: 0.0558 - val_accuracy: 0.9855\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds, \n",
    "                    epochs = 100, \n",
    "                    verbose = 2,\n",
    "                    validation_data = val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('data/history.csv', 'w')\n",
    "file.write(str(history.history))\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [2.128910541534424,\n",
       "  2.0240776538848877,\n",
       "  2.0229475498199463,\n",
       "  2.0204591751098633,\n",
       "  1.9563030004501343,\n",
       "  1.8470770120620728,\n",
       "  1.823891520500183,\n",
       "  1.812909722328186,\n",
       "  1.804916501045227,\n",
       "  1.7952795028686523,\n",
       "  1.783211588859558,\n",
       "  1.7695257663726807,\n",
       "  1.7525672912597656,\n",
       "  1.7280669212341309,\n",
       "  1.702354907989502,\n",
       "  1.6699520349502563,\n",
       "  1.6384539604187012,\n",
       "  1.6066248416900635,\n",
       "  1.5838068723678589,\n",
       "  1.5690088272094727,\n",
       "  1.550519347190857,\n",
       "  1.5372772216796875,\n",
       "  1.5242478847503662,\n",
       "  1.5111465454101562,\n",
       "  1.496944785118103,\n",
       "  1.483751654624939,\n",
       "  1.471705675125122,\n",
       "  1.4601165056228638,\n",
       "  1.44795823097229,\n",
       "  1.435286283493042,\n",
       "  1.4224687814712524,\n",
       "  1.4096884727478027,\n",
       "  1.3960256576538086,\n",
       "  1.3821990489959717,\n",
       "  1.3688592910766602,\n",
       "  1.3563060760498047,\n",
       "  1.3442429304122925,\n",
       "  1.3330174684524536,\n",
       "  1.322096824645996,\n",
       "  1.312050461769104,\n",
       "  1.3020037412643433,\n",
       "  1.2927168607711792,\n",
       "  1.2831826210021973,\n",
       "  1.2741025686264038,\n",
       "  1.2646355628967285,\n",
       "  1.2554219961166382,\n",
       "  1.2461425065994263,\n",
       "  1.2358895540237427,\n",
       "  1.225920557975769,\n",
       "  1.2154066562652588,\n",
       "  1.2027034759521484,\n",
       "  1.190155029296875,\n",
       "  1.1693813800811768,\n",
       "  1.1240297555923462,\n",
       "  0.9873006343841553,\n",
       "  0.8542080521583557,\n",
       "  0.772790253162384,\n",
       "  0.7080457806587219,\n",
       "  0.6558690071105957,\n",
       "  0.6035754084587097,\n",
       "  0.5484377145767212,\n",
       "  0.4941730201244354,\n",
       "  0.43476077914237976,\n",
       "  0.37531715631484985,\n",
       "  0.318543016910553,\n",
       "  0.27585309743881226,\n",
       "  0.24246446788311005,\n",
       "  0.2230304777622223,\n",
       "  0.2029024362564087,\n",
       "  0.18048112094402313,\n",
       "  0.16907374560832977,\n",
       "  0.1576118767261505,\n",
       "  0.14974406361579895,\n",
       "  0.13192003965377808,\n",
       "  0.1420438140630722,\n",
       "  0.12964163720607758,\n",
       "  0.11805539578199387,\n",
       "  0.11772328615188599,\n",
       "  0.10813779383897781,\n",
       "  0.11282779276371002,\n",
       "  0.10073108971118927,\n",
       "  0.10008113086223602,\n",
       "  0.09227646142244339,\n",
       "  0.08699198812246323,\n",
       "  0.0872216671705246,\n",
       "  0.0930916890501976,\n",
       "  0.08575065433979034,\n",
       "  0.08144671469926834,\n",
       "  0.0744653046131134,\n",
       "  0.08835005760192871,\n",
       "  0.06967432051897049,\n",
       "  0.0635358914732933,\n",
       "  0.08333674818277359,\n",
       "  0.05990513414144516,\n",
       "  0.052539363503456116,\n",
       "  0.06610340625047684,\n",
       "  0.06404957920312881,\n",
       "  0.049754101783037186,\n",
       "  0.06044522672891617,\n",
       "  0.0453740693628788],\n",
       " 'accuracy': [0.19889326393604279,\n",
       "  0.20158013701438904,\n",
       "  0.2027316689491272,\n",
       "  0.2032114714384079,\n",
       "  0.24332277476787567,\n",
       "  0.2884880006313324,\n",
       "  0.29462942481040955,\n",
       "  0.29894763231277466,\n",
       "  0.30380961298942566,\n",
       "  0.3098231256008148,\n",
       "  0.3163803815841675,\n",
       "  0.32229793071746826,\n",
       "  0.32684004306793213,\n",
       "  0.33736366033554077,\n",
       "  0.3519175946712494,\n",
       "  0.36663147807121277,\n",
       "  0.3757796883583069,\n",
       "  0.3865272104740143,\n",
       "  0.3922528326511383,\n",
       "  0.39733871817588806,\n",
       "  0.40271246433258057,\n",
       "  0.40818220376968384,\n",
       "  0.4118606746196747,\n",
       "  0.41589099168777466,\n",
       "  0.42091289162635803,\n",
       "  0.42366376519203186,\n",
       "  0.42810991406440735,\n",
       "  0.4322042167186737,\n",
       "  0.4347951114177704,\n",
       "  0.43642646074295044,\n",
       "  0.4409045875072479,\n",
       "  0.4469820559024811,\n",
       "  0.45248377323150635,\n",
       "  0.4572177827358246,\n",
       "  0.45974475145339966,\n",
       "  0.4644787907600403,\n",
       "  0.4678053855895996,\n",
       "  0.4730831980705261,\n",
       "  0.47772127389907837,\n",
       "  0.48136773705482483,\n",
       "  0.48613375425338745,\n",
       "  0.48958832025527954,\n",
       "  0.49441832304000854,\n",
       "  0.4975849986076355,\n",
       "  0.501071572303772,\n",
       "  0.5047500133514404,\n",
       "  0.5100917816162109,\n",
       "  0.5153376460075378,\n",
       "  0.5203915238380432,\n",
       "  0.5278763771057129,\n",
       "  0.5355852246284485,\n",
       "  0.5447973608970642,\n",
       "  0.5606627464294434,\n",
       "  0.5935770869255066,\n",
       "  0.6669225692749023,\n",
       "  0.714198887348175,\n",
       "  0.7437226176261902,\n",
       "  0.7666570544242859,\n",
       "  0.7870645523071289,\n",
       "  0.8051050901412964,\n",
       "  0.8252567052841187,\n",
       "  0.8430092930793762,\n",
       "  0.8638326525688171,\n",
       "  0.8855516314506531,\n",
       "  0.9048715829849243,\n",
       "  0.9184339046478271,\n",
       "  0.9291494488716125,\n",
       "  0.9369542002677917,\n",
       "  0.9413363933563232,\n",
       "  0.9501647353172302,\n",
       "  0.9524997472763062,\n",
       "  0.9563061594963074,\n",
       "  0.9588651061058044,\n",
       "  0.9632792472839355,\n",
       "  0.9606563448905945,\n",
       "  0.9636951088905334,\n",
       "  0.9675654768943787,\n",
       "  0.9670857191085815,\n",
       "  0.969868540763855,\n",
       "  0.96897292137146,\n",
       "  0.9719476699829102,\n",
       "  0.971723735332489,\n",
       "  0.9740588068962097,\n",
       "  0.9753702282905579,\n",
       "  0.9760419726371765,\n",
       "  0.9742826819419861,\n",
       "  0.9763618111610413,\n",
       "  0.9778971672058105,\n",
       "  0.979592502117157,\n",
       "  0.9762978553771973,\n",
       "  0.9806160926818848,\n",
       "  0.9825032949447632,\n",
       "  0.9787288308143616,\n",
       "  0.9838787317276001,\n",
       "  0.9852221608161926,\n",
       "  0.9822474122047424,\n",
       "  0.9824712872505188,\n",
       "  0.9860857725143433,\n",
       "  0.9830790162086487,\n",
       "  0.9876211285591125],\n",
       " 'val_loss': [2.0184197425842285,\n",
       "  2.0166563987731934,\n",
       "  2.015683889389038,\n",
       "  2.0090138912200928,\n",
       "  1.8688522577285767,\n",
       "  1.8290085792541504,\n",
       "  1.816759705543518,\n",
       "  1.8085649013519287,\n",
       "  1.7995299100875854,\n",
       "  1.788666844367981,\n",
       "  1.7750821113586426,\n",
       "  1.758180022239685,\n",
       "  1.7327402830123901,\n",
       "  1.711836338043213,\n",
       "  1.6846613883972168,\n",
       "  1.6512056589126587,\n",
       "  1.617372989654541,\n",
       "  1.5966907739639282,\n",
       "  1.5710866451263428,\n",
       "  1.5476287603378296,\n",
       "  1.5345314741134644,\n",
       "  1.5218100547790527,\n",
       "  1.5111010074615479,\n",
       "  1.4957903623580933,\n",
       "  1.4808536767959595,\n",
       "  1.4691402912139893,\n",
       "  1.4593816995620728,\n",
       "  1.450135588645935,\n",
       "  1.4412118196487427,\n",
       "  1.4307252168655396,\n",
       "  1.4173338413238525,\n",
       "  1.403180718421936,\n",
       "  1.3893320560455322,\n",
       "  1.3734018802642822,\n",
       "  1.3626317977905273,\n",
       "  1.354483962059021,\n",
       "  1.3471852540969849,\n",
       "  1.3383368253707886,\n",
       "  1.3297770023345947,\n",
       "  1.323940634727478,\n",
       "  1.3172831535339355,\n",
       "  1.3117780685424805,\n",
       "  1.3053289651870728,\n",
       "  1.2980878353118896,\n",
       "  1.2909557819366455,\n",
       "  1.2835323810577393,\n",
       "  1.2777990102767944,\n",
       "  1.2734471559524536,\n",
       "  1.2652021646499634,\n",
       "  1.254277229309082,\n",
       "  1.2448108196258545,\n",
       "  1.2328338623046875,\n",
       "  1.2143570184707642,\n",
       "  1.1210037469863892,\n",
       "  0.9337922930717468,\n",
       "  0.8288806080818176,\n",
       "  0.7772586345672607,\n",
       "  0.7141255140304565,\n",
       "  0.6589951515197754,\n",
       "  0.6220329403877258,\n",
       "  0.5436580181121826,\n",
       "  0.48262515664100647,\n",
       "  0.4157608449459076,\n",
       "  0.4054540991783142,\n",
       "  0.28984445333480835,\n",
       "  0.24690420925617218,\n",
       "  0.2277662456035614,\n",
       "  0.22891147434711456,\n",
       "  0.19086618721485138,\n",
       "  0.1935204416513443,\n",
       "  0.14968548715114594,\n",
       "  0.14980170130729675,\n",
       "  0.15074670314788818,\n",
       "  0.133819118142128,\n",
       "  0.1224593073129654,\n",
       "  0.16419410705566406,\n",
       "  0.335502564907074,\n",
       "  0.10353787988424301,\n",
       "  0.10147745162248611,\n",
       "  0.23506119847297668,\n",
       "  0.09257572889328003,\n",
       "  0.09019684046506882,\n",
       "  0.0888923853635788,\n",
       "  0.07995232939720154,\n",
       "  0.0899442657828331,\n",
       "  0.08211798220872879,\n",
       "  0.07523977756500244,\n",
       "  0.06818180531263351,\n",
       "  0.07293891161680222,\n",
       "  0.06940341740846634,\n",
       "  0.07217559218406677,\n",
       "  0.0718642845749855,\n",
       "  0.06560438126325607,\n",
       "  0.19975219666957855,\n",
       "  0.06454209983348846,\n",
       "  0.0661119744181633,\n",
       "  0.07190903276205063,\n",
       "  0.05605721101164818,\n",
       "  0.058460213243961334,\n",
       "  0.05578627809882164],\n",
       " 'val_accuracy': [0.20034542679786682,\n",
       "  0.20034542679786682,\n",
       "  0.1999616175889969,\n",
       "  0.1998656690120697,\n",
       "  0.27816158533096313,\n",
       "  0.29188254475593567,\n",
       "  0.2963922619819641,\n",
       "  0.2996545732021332,\n",
       "  0.3043561577796936,\n",
       "  0.3061792254447937,\n",
       "  0.3085780143737793,\n",
       "  0.3207637667655945,\n",
       "  0.3266167640686035,\n",
       "  0.3411053419113159,\n",
       "  0.3603914678096771,\n",
       "  0.37344080209732056,\n",
       "  0.38073307275772095,\n",
       "  0.38399538397789,\n",
       "  0.3954135477542877,\n",
       "  0.3983880281448364,\n",
       "  0.4028017520904541,\n",
       "  0.4080790579319,\n",
       "  0.40980619192123413,\n",
       "  0.4167146384716034,\n",
       "  0.4210324287414551,\n",
       "  0.4232392907142639,\n",
       "  0.42611783742904663,\n",
       "  0.4336020052433014,\n",
       "  0.4376319348812103,\n",
       "  0.43878334760665894,\n",
       "  0.44118210673332214,\n",
       "  0.44463634490966797,\n",
       "  0.4509690999984741,\n",
       "  0.45634233951568604,\n",
       "  0.4620994031429291,\n",
       "  0.46641719341278076,\n",
       "  0.47015929222106934,\n",
       "  0.4746689796447754,\n",
       "  0.4775474965572357,\n",
       "  0.4783151149749756,\n",
       "  0.47985032200813293,\n",
       "  0.48224908113479614,\n",
       "  0.4854154586791992,\n",
       "  0.4897332489490509,\n",
       "  0.492899626493454,\n",
       "  0.4980809688568115,\n",
       "  0.5012473464012146,\n",
       "  0.5035501718521118,\n",
       "  0.5091153383255005,\n",
       "  0.5137209892272949,\n",
       "  0.5226444005966187,\n",
       "  0.5335828065872192,\n",
       "  0.5505661368370056,\n",
       "  0.61341392993927,\n",
       "  0.6873920559883118,\n",
       "  0.7219343781471252,\n",
       "  0.7372865080833435,\n",
       "  0.7639608383178711,\n",
       "  0.788908064365387,\n",
       "  0.8022452592849731,\n",
       "  0.8319900035858154,\n",
       "  0.8520437479019165,\n",
       "  0.8769909739494324,\n",
       "  0.8803492784500122,\n",
       "  0.9160429835319519,\n",
       "  0.9304355978965759,\n",
       "  0.9372481107711792,\n",
       "  0.9356169700622559,\n",
       "  0.9478986859321594,\n",
       "  0.9488582015037537,\n",
       "  0.9618115425109863,\n",
       "  0.9600844383239746,\n",
       "  0.9607560634613037,\n",
       "  0.9655536413192749,\n",
       "  0.9671847820281982,\n",
       "  0.9578775763511658,\n",
       "  0.9122049808502197,\n",
       "  0.9726539850234985,\n",
       "  0.9725580215454102,\n",
       "  0.9375360012054443,\n",
       "  0.9756284952163696,\n",
       "  0.9753406047821045,\n",
       "  0.9762041568756104,\n",
       "  0.9779313206672668,\n",
       "  0.9755325317382812,\n",
       "  0.977067768573761,\n",
       "  0.9799462556838989,\n",
       "  0.9811936020851135,\n",
       "  0.9802341461181641,\n",
       "  0.9805219769477844,\n",
       "  0.9802341461181641,\n",
       "  0.9801381826400757,\n",
       "  0.981769323348999,\n",
       "  0.9483784437179565,\n",
       "  0.9834005236625671,\n",
       "  0.9827288389205933,\n",
       "  0.9799462556838989,\n",
       "  0.9849357008934021,\n",
       "  0.9832085967063904,\n",
       "  0.9855114221572876]}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f1a13dbb210>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize = (7,7))\n",
    "styles = ['-','--', '-.',':']\n",
    "d_join = ['miter', 'round', 'bevel', 'miter']\n",
    "d_cap = ['butt', 'round', 'projecting', 'butt']\n",
    "s_cap = ['butt', 'round', 'projecting', 'butt']\n",
    "s_join = ['miter', 'round', 'bevel', 'miter']\n",
    "\n",
    "for idx, key in enumerate(history.history.keys()):\n",
    "    ax.plot(history.history[key], \n",
    "            label = key, \n",
    "            linestyle = styles[idx],\n",
    "            linewidth = 2,\n",
    "            alpha = .8,\n",
    "            dash_joinstyle = d_join[idx],\n",
    "            dash_capstyle = d_cap[idx],\n",
    "            solid_capstyle = s_cap[idx],\n",
    "            solid_joinstyle = s_join[idx]\n",
    "           )\n",
    "\n",
    "ax.set_xlabel('Epochs', fontsize = 15)\n",
    "ax.set_title('Mana Cost Classification Accuracy', fontsize = 15)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape mismatch: The shape of labels (received (32, 1)) should equal the shape of logits except for the last dimension (received (32, 1000, 32)).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-fb6cc4fde80c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     epochs=epochs)\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    803\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m         \u001b[0;34m\"\"\"Runs a training execution with one step.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 805\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mstep_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mstep_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m    793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m       \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    796\u001b[0m       outputs = reduce_per_replica(\n\u001b[1;32m    797\u001b[0m           outputs, self.distribute_strategy, reduction='first')\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1257\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   1258\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 1259\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2728\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2729\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2730\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2732\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3415\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3416\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3417\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3419\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    570\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUNSPECIFIED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    789\u001b[0m         \u001b[0;31m# Ensure counter is updated only if `train_step` succeeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    754\u001b[0m       \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m       loss = self.compiled_loss(\n\u001b[0;32m--> 756\u001b[0;31m           y, y_pred, sample_weight, regularization_losses=self.losses)\n\u001b[0m\u001b[1;32m    757\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompiled_metrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/compile_utils.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, y_true, y_pred, sample_weight, regularization_losses)\u001b[0m\n\u001b[1;32m    201\u001b[0m       \u001b[0my_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatch_dtype_and_rank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m       \u001b[0msw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m       \u001b[0mloss_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m       \u001b[0mloss_metric_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/losses.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[1;32m    150\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mcall_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m       \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m       return losses_utils.compute_weighted_loss(\n\u001b[1;32m    154\u001b[0m           losses, sample_weight, reduction=self._get_reduction())\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/losses.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, y_true, y_pred)\u001b[0m\n\u001b[1;32m    254\u001b[0m           y_pred, y_true)\n\u001b[1;32m    255\u001b[0m     \u001b[0mag_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mag_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/losses.py\u001b[0m in \u001b[0;36msparse_categorical_crossentropy\u001b[0;34m(y_true, y_pred, from_logits, axis)\u001b[0m\n\u001b[1;32m   1567\u001b[0m   \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1568\u001b[0m   return K.sparse_categorical_crossentropy(\n\u001b[0;32m-> 1569\u001b[0;31m       y_true, y_pred, from_logits=from_logits, axis=axis)\n\u001b[0m\u001b[1;32m   1570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36msparse_categorical_crossentropy\u001b[0;34m(target, output, from_logits, axis)\u001b[0m\n\u001b[1;32m   4942\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4943\u001b[0m     res = nn.sparse_softmax_cross_entropy_with_logits_v2(\n\u001b[0;32m-> 4944\u001b[0;31m         labels=target, logits=output)\n\u001b[0m\u001b[1;32m   4945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4946\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mupdate_shape\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0moutput_rank\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36msparse_softmax_cross_entropy_with_logits_v2\u001b[0;34m(labels, logits, name)\u001b[0m\n\u001b[1;32m   4239\u001b[0m   \"\"\"\n\u001b[1;32m   4240\u001b[0m   return sparse_softmax_cross_entropy_with_logits(\n\u001b[0;32m-> 4241\u001b[0;31m       labels=labels, logits=logits, name=name)\n\u001b[0m\u001b[1;32m   4242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36msparse_softmax_cross_entropy_with_logits\u001b[0;34m(_sentinel, labels, logits, name)\u001b[0m\n\u001b[1;32m   4154\u001b[0m                        \u001b[0;34m\"should equal the shape of logits except for the last \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4155\u001b[0m                        \"dimension (received %s).\" % (labels_static_shape,\n\u001b[0;32m-> 4156\u001b[0;31m                                                      logits.get_shape()))\n\u001b[0m\u001b[1;32m   4157\u001b[0m     \u001b[0;31m# Check if no reshapes are required.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4158\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape mismatch: The shape of labels (received (32, 1)) should equal the shape of logits except for the last dimension (received (32, 1000, 32))."
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "   # feature_layer,\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=len(encoder.get_vocabulary()),\n",
    "        output_dim=64,\n",
    "        embeddings_regularizer = tf.keras.regularizers.l1_l2()\n",
    "\n",
    "        ),\n",
    "    #tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(32)\n",
    "])\n",
    "\n",
    "model.compile(loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
    "              optimizer = tf.keras.optimizers.Adam(1e-4),\n",
    "              metrics = tf.metrics.SparseCategoricalAccuracy(),\n",
    "              run_eagerly = True)\n",
    "\n",
    "\n",
    "epochs = 10\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=epochs)\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    #feature_layer,\n",
    "    layers.Embedding(len(encoder.get_vocabulary()), 16),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.GlobalAveragePooling1D(),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(1)])\n",
    "\n",
    "model.compile(loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              optimizer = tf.keras.optimizers.Adam(1e-4),\n",
    "              metrics = tf.metrics.CategoricalAccuracy())\n",
    "\n",
    "epochs = 10\n",
    "history = model.fit(\n",
    "    experiment_training,\n",
    "    validation_data=experiment_testing,\n",
    "    epochs=epochs)\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  feature_layer,\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dropout(.1),\n",
    "  layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(experiment_training,\n",
    "          validation_data=experiment_validating,\n",
    "          epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
